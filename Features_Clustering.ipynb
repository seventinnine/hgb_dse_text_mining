{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e8d663-1c71-4786-aef1-bd848bd6a8b6",
   "metadata": {},
   "source": [
    "### Load the data - for the upcoming exercises we will only use the english dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e145466-8d4a-4cc4-a4b6-aa4b1b3562ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classes_en = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tech\"}\n",
    "train_en = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/master/data/AGNews/train.csv\", \n",
    "                       names = [\"Label\", \"Title\", \"Article\"],\n",
    "                       encoding = \"utf-8\")\n",
    "test_en = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/master/data/AGNews/test.csv\", \n",
    "                      names = [\"Label\", \"Title\", \"Article\"],\n",
    "                      encoding = \"utf-8\")\n",
    "\n",
    "sample = train_en.sample(5000)\n",
    "labels = [classes_en[int(row[\"Label\"])] for i, row in sample.iterrows()]\n",
    "docs = [row[\"Article\"] for i, row in sample.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d56669-7b65-4a91-9440-fbf6003e753e",
   "metadata": {},
   "source": [
    "# **Feature Representations**\n",
    "\n",
    "### We have already worked with TF-IDF with Gensim, for this exercise we will generate the TF-IDF matrix with sklearn\n",
    "\n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html]( https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484a2b43-7c5b-4e7c-8746-31819b508add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 16242)\n",
      "(16242,)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as nltkStopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords_en = list(nltkStopwords.words(\"english\"))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents = \"unicode\",\n",
    "                                   stop_words = stopwords_en)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "tfidf_features_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(X_tfidf.shape)\n",
    "print(tfidf_features_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b445d8b-7a56-4dfa-87c5-b8caf570077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(X_tfidf.A, columns = tfidf_features_names)\n",
    "tfidf[\"Label\"] = labels\n",
    "# tfidf.to_csv(\"tfidf_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48bebbd-9bf7-4fe4-8369-47d3117573fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000bn</th>\n",
       "      <th>000mph</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>0013</th>\n",
       "      <th>005930</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zook</th>\n",
       "      <th>zope</th>\n",
       "      <th>zos</th>\n",
       "      <th>zseries</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zwiki</th>\n",
       "      <th>zy</th>\n",
       "      <th>zydrunas</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000bn  000mph  000th  001  0013  005930   01   02  ...  zook  \\\n",
       "0  0.0  0.0    0.0     0.0    0.0  0.0   0.0     0.0  0.0  0.0  ...   0.0   \n",
       "1  0.0  0.0    0.0     0.0    0.0  0.0   0.0     0.0  0.0  0.0  ...   0.0   \n",
       "2  0.0  0.0    0.0     0.0    0.0  0.0   0.0     0.0  0.0  0.0  ...   0.0   \n",
       "3  0.0  0.0    0.0     0.0    0.0  0.0   0.0     0.0  0.0  0.0  ...   0.0   \n",
       "4  0.0  0.0    0.0     0.0    0.0  0.0   0.0     0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   zope  zos  zseries  zurich  zvonareva  zwiki   zy  zydrunas   Label  \n",
       "0   0.0  0.0      0.0     0.0        0.0    0.0  0.0       0.0  Sports  \n",
       "1   0.0  0.0      0.0     0.0        0.0    0.0  0.0       0.0   World  \n",
       "2   0.0  0.0      0.0     0.0        0.0    0.0  0.0       0.0  Sports  \n",
       "3   0.0  0.0      0.0     0.0        0.0    0.0  0.0       0.0  Sports  \n",
       "4   0.0  0.0      0.0     0.0        0.0    0.0  0.0       0.0   World  \n",
       "\n",
       "[5 rows x 16243 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2b528-845d-4545-842f-8680d1427e71",
   "metadata": {},
   "source": [
    "### Another way of representing text is using a word count matrix which consists just of the absolute term frequencies\n",
    "\n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd5cdd9-d133-4ab4-8265-dcbd7a6efa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 16242)\n",
      "(16242,)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(strip_accents = \"unicode\",\n",
    "                                   stop_words = stopwords_en)\n",
    "\n",
    "X_counts = count_vectorizer.fit_transform(docs)\n",
    "counts_features_names = count_vectorizer.get_feature_names_out()\n",
    "print(X_counts.shape)\n",
    "print(counts_features_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f56643-949c-4691-afe8-0f80ebbc4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(X_counts.A, columns = counts_features_names)\n",
    "counts[\"Label\"] = labels\n",
    "# counts.to_csv(\"counts_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343866d6-47cf-477a-8f3c-e8566981d74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000bn</th>\n",
       "      <th>000mph</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>0013</th>\n",
       "      <th>005930</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zook</th>\n",
       "      <th>zope</th>\n",
       "      <th>zos</th>\n",
       "      <th>zseries</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zwiki</th>\n",
       "      <th>zy</th>\n",
       "      <th>zydrunas</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000bn  000mph  000th  001  0013  005930  01  02  ...  zook  zope  \\\n",
       "0   0    0      0       0      0    0     0       0   0   0  ...     0     0   \n",
       "1   0    0      0       0      0    0     0       0   0   0  ...     0     0   \n",
       "2   0    0      0       0      0    0     0       0   0   0  ...     0     0   \n",
       "3   0    0      0       0      0    0     0       0   0   0  ...     0     0   \n",
       "4   0    0      0       0      0    0     0       0   0   0  ...     0     0   \n",
       "\n",
       "   zos  zseries  zurich  zvonareva  zwiki  zy  zydrunas   Label  \n",
       "0    0        0       0          0      0   0         0  Sports  \n",
       "1    0        0       0          0      0   0         0   World  \n",
       "2    0        0       0          0      0   0         0  Sports  \n",
       "3    0        0       0          0      0   0         0  Sports  \n",
       "4    0        0       0          0      0   0         0   World  \n",
       "\n",
       "[5 rows x 16243 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836202c-726f-49a7-9a41-25829f021ea7",
   "metadata": {},
   "source": [
    "### Last but not least we can also use embeddings like Word2Vec or Doc2Vec to represent our documents\n",
    "\n",
    "You can train these embeddings with your own data by yourself e.g. as described here [https://www.tensorflow.org/tutorials/text/word2vec](https://www.tensorflow.org/tutorials/text/word2vec)  \n",
    "or you use a pre-trained model like spaCy (remember our first exercise).\n",
    "\n",
    "Since creating these embeddings may take some time, I did that beforehand but this is the code to do so:\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc2vec = [nlp(doc).vector for doc in docs]\n",
    "vectors = np.array(doc2vec)\n",
    "vec_space = pd.DataFrame(vectors)\n",
    "vec_space[\"Label\"] = labels\n",
    "vec_space.to_csv(\"doc2vec_en.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3b9cd-04a9-4377-ba83-99a8953c1922",
   "metadata": {},
   "source": [
    "Loading the document vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f790bd-f12c-4f44-a46f-8405953fc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 300)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "vec_space = pd.read_csv(\"https://raw.githubusercontent.com/michabirklbauer/hgb_dse_text_mining/develop/data/Doc2Vec/doc2vec_en.csv\", index_col = 0)\n",
    "X_doc2vec = vec_space.loc[:, vec_space.columns != \"Label\"].values\n",
    "Y_doc2vec = vec_space[\"Label\"].values\n",
    "print(X_doc2vec.shape)\n",
    "print(Y_doc2vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1f4d4-6971-4291-a6aa-f4cf20cd5f7a",
   "metadata": {},
   "source": [
    "# **Clustering**\n",
    "\n",
    "Each of the above feature represenations can be used for both clustering and classification. We are going to use kMeans clustering in the following and assess the quality of our clusters using silhoutte plots.\n",
    "\n",
    "You should:\n",
    "- Read the documentation about kMeans in sklearn [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "- Try out different numbers of clusters\n",
    "- Try out the different feature represenations\n",
    "- What works well and what doesn't work well?\n",
    "- Which distance metric does sklearn's implemenation of kMeans use?\n",
    "\n",
    "A function to plot the silhouette plot is given. More about silhouette plots can be found here [https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebc857a-731f-4770-9a82-26e1a0700e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2443bb4-4c0d-4e12-aa7d-024d5fad8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "def silhouette_plot(X, cluster_labels):\n",
    "    n_clusters = len(set(cluster_labels))\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"Silhouette Avg.:\", silhouette_avg)\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    # ax1.set_xlim([-1, 1])\n",
    "    ax1.set_ylim([0, X.shape[0] + (n_clusters + 1) * 100])\n",
    "    y_lower = 100\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 100\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])\n",
    "    #ax1.set_xticks([-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d2954-1f02-4ca9-b564-be1c3bb8796d",
   "metadata": {},
   "source": [
    "**How to plot silhouette:**\n",
    "```python\n",
    "silhouette_plot(X_tfidf, cluster_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ebce1-69e0-43d4-8d16-ea11a448ae63",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
